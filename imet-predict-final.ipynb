{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['06-01-results', '05-28-results', '06-02-results', 'imet-2019-fgvc6', '05-30-results']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import glob\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input/\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from itertools import islice\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import warnings\n",
    "from typing import Dict\n",
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import math\n",
    "import random\n",
    "from typing import Callable, List\n",
    "from datetime import datetime\n",
    "import json\n",
    "import glob\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn, cuda\n",
    "from torch.nn import functional as F\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import (\n",
    "    ToTensor, Normalize, Compose, Resize, CenterCrop, RandomCrop,\n",
    "    RandomHorizontalFlip)\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from PIL import Image\n",
    "import cv2\n",
    "cv2.setNumThreads(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('../input/imet-2019-fgvc6')\n",
    "N_CLASSES = 1103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "pretrained_settings = {\n",
    "    'inceptionv4': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionv4-8e4777a0.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 299, 299],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1000\n",
    "        },\n",
    "        'imagenet+background': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionv4-8e4777a0.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 299, 299],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1001\n",
    "        }\n",
    "    },\n",
    "    'senet154': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet50': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet50-ce0d4300.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet101': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnet152': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnet152-d17c99b7.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext50_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'se_resnext101_32x4d': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/se_resnext101_32x4d-3b2fe3d8.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 224, 224],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225],\n",
    "            'num_classes': 1000\n",
    "        }\n",
    "    },\n",
    "    'inceptionresnetv2': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 299, 299],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1000\n",
    "        },\n",
    "        'imagenet+background': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/inceptionresnetv2-520b38e4.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 299, 299],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1001\n",
    "        }\n",
    "    },\n",
    "    'pnasnet5large': {\n",
    "        'imagenet': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/pnasnet5large-bf079911.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 331, 331],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1000\n",
    "        },\n",
    "        'imagenet+background': {\n",
    "            'url': 'http://data.lip6.fr/cadene/pretrainedmodels/pnasnet5large-bf079911.pth',\n",
    "            'input_space': 'RGB',\n",
    "            'input_size': [3, 331, 331],\n",
    "            'input_range': [0, 1],\n",
    "            'mean': [0.5, 0.5, 0.5],\n",
    "            'std': [0.5, 0.5, 0.5],\n",
    "            'num_classes': 1001\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes,\n",
    "                              kernel_size=kernel_size, stride=stride,\n",
    "                              padding=padding, bias=False) # verify bias false\n",
    "        self.bn = nn.BatchNorm2d(out_planes,\n",
    "                                 eps=0.001, # value found in tensorflow\n",
    "                                 momentum=0.1, # default pytorch value\n",
    "                                 affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Mixed_3a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_3a, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.maxpool(x)\n",
    "        x1 = self.conv(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_4a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_4a, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_5a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_5a, self).__init__()\n",
    "        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv(x)\n",
    "        x1 = self.maxpool(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Reduction_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_A, self).__init__()\n",
    "        self.branch0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(384, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(224, 256, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_B, self).__init__()\n",
    "        self.branch0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Reduction_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_B, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(320, 320, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Inception_C(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_C, self).__init__()\n",
    "\n",
    "        self.branch0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.branch1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "\n",
    "        self.branch2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.branch2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        self.branch2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.branch2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "\n",
    "        x1_0 = self.branch1_0(x)\n",
    "        x1_1a = self.branch1_1a(x1_0)\n",
    "        x1_1b = self.branch1_1b(x1_0)\n",
    "        x1 = torch.cat((x1_1a, x1_1b), 1)\n",
    "\n",
    "        x2_0 = self.branch2_0(x)\n",
    "        x2_1 = self.branch2_1(x2_0)\n",
    "        x2_2 = self.branch2_2(x2_1)\n",
    "        x2_3a = self.branch2_3a(x2_2)\n",
    "        x2_3b = self.branch2_3b(x2_2)\n",
    "        x2 = torch.cat((x2_3a, x2_3b), 1)\n",
    "\n",
    "        x3 = self.branch3(x)\n",
    "\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class InceptionV4(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1001):\n",
    "        super(InceptionV4, self).__init__()\n",
    "        # Special attributs\n",
    "        self.input_space = None\n",
    "        self.input_size = (299, 299, 3)\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        # Modules\n",
    "        self.features = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1),\n",
    "            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            Mixed_3a(),\n",
    "            Mixed_4a(),\n",
    "            Mixed_5a(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Reduction_A(), # Mixed_6a\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Reduction_B(), # Mixed_7a\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "            Inception_C()\n",
    "        )\n",
    "        self.last_linear = nn.Linear(1536, num_classes)\n",
    "\n",
    "    def logits(self, features):\n",
    "        #Allows image of any size to be processed\n",
    "        adaptiveAvgPoolWidth = features.shape[2]\n",
    "        x = F.avg_pool2d(features, kernel_size=adaptiveAvgPoolWidth)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def inceptionv4(num_classes=1000, pretrained='imagenet'):\n",
    "    if pretrained:\n",
    "        settings = pretrained_settings['inceptionv4'][pretrained]\n",
    "        assert num_classes == settings['num_classes'], \\\n",
    "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
    "\n",
    "        # both 'imagenet'&'imagenet+background' are loaded from same parameters\n",
    "        model = InceptionV4(num_classes=1001)\n",
    "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "\n",
    "        if pretrained == 'imagenet':\n",
    "            new_last_linear = nn.Linear(1536, 1000)\n",
    "            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n",
    "            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n",
    "            model.last_linear = new_last_linear\n",
    "\n",
    "        model.input_space = settings['input_space']\n",
    "        model.input_size = settings['input_size']\n",
    "        model.input_range = settings['input_range']\n",
    "        model.mean = settings['mean']\n",
    "        model.std = settings['std']\n",
    "    else:\n",
    "        model = InceptionV4(num_classes=num_classes)\n",
    "    return model\n",
    "    \n",
    "class SEModule(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1,\n",
    "                             padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for bottlenecks that implements `forward()` method.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out = self.se_module(out) + residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class SEBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    Bottleneck for SENet154.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes * 2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes * 2)\n",
    "        self.conv2 = nn.Conv2d(planes * 2, planes * 4, kernel_size=3,\n",
    "                               stride=stride, padding=1, groups=groups,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes * 4)\n",
    "        self.conv3 = nn.Conv2d(planes * 4, planes * 4, kernel_size=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNetBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNet bottleneck with a Squeeze-and-Excitation module. It follows Caffe\n",
    "    implementation and uses `stride=stride` in `conv1` and not in `conv2`\n",
    "    (the latter is used in the torchvision implementation of ResNet).\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None):\n",
    "        super(SEResNetBottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False,\n",
    "                               stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1,\n",
    "                               groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SEResNeXtBottleneck(Bottleneck):\n",
    "    \"\"\"\n",
    "    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n",
    "    \"\"\"\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, groups, reduction, stride=1,\n",
    "                 downsample=None, base_width=4):\n",
    "        super(SEResNeXtBottleneck, self).__init__()\n",
    "        width = math.floor(planes * (base_width / 64)) * groups\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False,\n",
    "                               stride=1)\n",
    "        self.bn1 = nn.BatchNorm2d(width)\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=stride,\n",
    "                               padding=1, groups=groups, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(width)\n",
    "        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.se_module = SEModule(planes * 4, reduction=reduction)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, groups, reduction, dropout_p=0.2,\n",
    "                 inplanes=128, input_3x3=True, downsample_kernel_size=3,\n",
    "                 downsample_padding=1, num_classes=1000):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        block (nn.Module): Bottleneck class.\n",
    "            - For SENet154: SEBottleneck\n",
    "            - For SE-ResNet models: SEResNetBottleneck\n",
    "            - For SE-ResNeXt models:  SEResNeXtBottleneck\n",
    "        layers (list of ints): Number of residual blocks for 4 layers of the\n",
    "            network (layer1...layer4).\n",
    "        groups (int): Number of groups for the 3x3 convolution in each\n",
    "            bottleneck block.\n",
    "            - For SENet154: 64\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models:  32\n",
    "        reduction (int): Reduction ratio for Squeeze-and-Excitation modules.\n",
    "            - For all models: 16\n",
    "        dropout_p (float or None): Drop probability for the Dropout layer.\n",
    "            If `None` the Dropout layer is not used.\n",
    "            - For SENet154: 0.2\n",
    "            - For SE-ResNet models: None\n",
    "            - For SE-ResNeXt models: None\n",
    "        inplanes (int):  Number of input channels for layer1.\n",
    "            - For SENet154: 128\n",
    "            - For SE-ResNet models: 64\n",
    "            - For SE-ResNeXt models: 64\n",
    "        input_3x3 (bool): If `True`, use three 3x3 convolutions instead of\n",
    "            a single 7x7 convolution in layer0.\n",
    "            - For SENet154: True\n",
    "            - For SE-ResNet models: False\n",
    "            - For SE-ResNeXt models: False\n",
    "        downsample_kernel_size (int): Kernel size for downsampling convolutions\n",
    "            in layer2, layer3 and layer4.\n",
    "            - For SENet154: 3\n",
    "            - For SE-ResNet models: 1\n",
    "            - For SE-ResNeXt models: 1\n",
    "        downsample_padding (int): Padding for downsampling convolutions in\n",
    "            layer2, layer3 and layer4.\n",
    "            - For SENet154: 1\n",
    "            - For SE-ResNet models: 0\n",
    "            - For SE-ResNeXt models: 0\n",
    "        num_classes (int): Number of outputs in `last_linear` layer.\n",
    "            - For all models: 1000\n",
    "        \"\"\"\n",
    "        super(SENet, self).__init__()\n",
    "        self.inplanes = inplanes\n",
    "        if input_3x3:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, 64, 3, stride=2, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(64)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "                ('conv2', nn.Conv2d(64, 64, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn2', nn.BatchNorm2d(64)),\n",
    "                ('relu2', nn.ReLU(inplace=True)),\n",
    "                ('conv3', nn.Conv2d(64, inplanes, 3, stride=1, padding=1,\n",
    "                                    bias=False)),\n",
    "                ('bn3', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu3', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        else:\n",
    "            layer0_modules = [\n",
    "                ('conv1', nn.Conv2d(3, inplanes, kernel_size=7, stride=2,\n",
    "                                    padding=3, bias=False)),\n",
    "                ('bn1', nn.BatchNorm2d(inplanes)),\n",
    "                ('relu1', nn.ReLU(inplace=True)),\n",
    "            ]\n",
    "        # To preserve compatibility with Caffe weights `ceil_mode=True`\n",
    "        # is used instead of `padding=1`.\n",
    "        layer0_modules.append(('pool', nn.MaxPool2d(3, stride=2,\n",
    "                                                    ceil_mode=True)))\n",
    "        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n",
    "        self.layer1 = self._make_layer(\n",
    "            block,\n",
    "            planes=64,\n",
    "            blocks=layers[0],\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=1,\n",
    "            downsample_padding=0\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block,\n",
    "            planes=128,\n",
    "            blocks=layers[1],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block,\n",
    "            planes=256,\n",
    "            blocks=layers[2],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block,\n",
    "            planes=512,\n",
    "            blocks=layers[3],\n",
    "            stride=2,\n",
    "            groups=groups,\n",
    "            reduction=reduction,\n",
    "            downsample_kernel_size=downsample_kernel_size,\n",
    "            downsample_padding=downsample_padding\n",
    "        )\n",
    "        self.avg_pool = nn.AvgPool2d(7, stride=1)\n",
    "        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n",
    "        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, groups, reduction, stride=1,\n",
    "                    downsample_kernel_size=1, downsample_padding=0):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=downsample_kernel_size, stride=stride,\n",
    "                          padding=downsample_padding, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, groups, reduction, stride,\n",
    "                            downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups, reduction))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def features(self, x):\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, x):\n",
    "        x = self.avg_pool(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def initialize_pretrained_model(model, num_classes, settings):\n",
    "    assert num_classes == settings['num_classes'], \\\n",
    "        'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "    model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "    model.input_space = settings['input_space']\n",
    "    model.input_size = settings['input_size']\n",
    "    model.input_range = settings['input_range']\n",
    "    model.mean = settings['mean']\n",
    "    model.std = settings['std']\n",
    "\n",
    "\n",
    "def senet154(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEBottleneck, [3, 8, 36, 3], groups=64, reduction=16,\n",
    "                  dropout_p=0.2, num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['senet154'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet50(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 6, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet50'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet101(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 4, 23, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet101'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnet152(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNetBottleneck, [3, 8, 36, 3], groups=1, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnet152'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext50_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 6, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext50_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "\n",
    "def se_resnext101_32x4d(num_classes=1000, pretrained='imagenet'):\n",
    "    model = SENet(SEResNeXtBottleneck, [3, 4, 23, 3], groups=32, reduction=16,\n",
    "                  dropout_p=None, inplanes=64, input_3x3=False,\n",
    "                  downsample_kernel_size=1, downsample_padding=0,\n",
    "                  num_classes=num_classes)\n",
    "    if pretrained is not None:\n",
    "        settings = pretrained_settings['se_resnext101_32x4d'][pretrained]\n",
    "        initialize_pretrained_model(model, num_classes, settings)\n",
    "    return model\n",
    "\n",
    "class Mixed_5b(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_5b, self).__init__()\n",
    "\n",
    "        self.branch0 = BasicConv2d(192, 96, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(192, 48, kernel_size=1, stride=1),\n",
    "            BasicConv2d(48, 64, kernel_size=5, stride=1, padding=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(192, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(192, 64, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Block35(nn.Module):\n",
    "\n",
    "    def __init__(self, scale=1.0):\n",
    "        super(Block35, self).__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "\n",
    "        self.branch0 = BasicConv2d(320, 32, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(320, 32, kernel_size=1, stride=1),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(320, 32, kernel_size=1, stride=1),\n",
    "            BasicConv2d(32, 48, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(48, 64, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(128, 320, kernel_size=1, stride=1)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        out = self.conv2d(out)\n",
    "        out = out * self.scale + x\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_6a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_6a, self).__init__()\n",
    "\n",
    "        self.branch0 = BasicConv2d(320, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(320, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(256, 384, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Block17(nn.Module):\n",
    "\n",
    "    def __init__(self, scale=1.0):\n",
    "        super(Block17, self).__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "\n",
    "        self.branch0 = BasicConv2d(1088, 192, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1088, 128, kernel_size=1, stride=1),\n",
    "            BasicConv2d(128, 160, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(160, 192, kernel_size=(7,1), stride=1, padding=(3,0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(384, 1088, kernel_size=1, stride=1)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        out = self.conv2d(out)\n",
    "        out = out * self.scale + x\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Mixed_7a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_7a, self).__init__()\n",
    "\n",
    "        self.branch0 = nn.Sequential(\n",
    "            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 384, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 288, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            BasicConv2d(1088, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 288, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(288, 320, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Block8(nn.Module):\n",
    "\n",
    "    def __init__(self, scale=1.0, noReLU=False):\n",
    "        super(Block8, self).__init__()\n",
    "\n",
    "        self.scale = scale\n",
    "        self.noReLU = noReLU\n",
    "\n",
    "        self.branch0 = BasicConv2d(2080, 192, kernel_size=1, stride=1)\n",
    "\n",
    "        self.branch1 = nn.Sequential(\n",
    "            BasicConv2d(2080, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,3), stride=1, padding=(0,1)),\n",
    "            BasicConv2d(224, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        )\n",
    "\n",
    "        self.conv2d = nn.Conv2d(448, 2080, kernel_size=1, stride=1)\n",
    "        if not self.noReLU:\n",
    "            self.relu = nn.ReLU(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.branch0(x)\n",
    "        x1 = self.branch1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        out = self.conv2d(out)\n",
    "        out = out * self.scale + x\n",
    "        if not self.noReLU:\n",
    "            out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class InceptionResNetV2(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1001):\n",
    "        super(InceptionResNetV2, self).__init__()\n",
    "        # Special attributs\n",
    "        self.input_space = None\n",
    "        self.input_size = (299, 299, 3)\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        # Modules\n",
    "        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n",
    "        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n",
    "        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n",
    "        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n",
    "        self.maxpool_5a = nn.MaxPool2d(3, stride=2)\n",
    "        self.mixed_5b = Mixed_5b()\n",
    "        self.repeat = nn.Sequential(\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17),\n",
    "            Block35(scale=0.17)\n",
    "        )\n",
    "        self.mixed_6a = Mixed_6a()\n",
    "        self.repeat_1 = nn.Sequential(\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10),\n",
    "            Block17(scale=0.10)\n",
    "        )\n",
    "        self.mixed_7a = Mixed_7a()\n",
    "        self.repeat_2 = nn.Sequential(\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20),\n",
    "            Block8(scale=0.20)\n",
    "        )\n",
    "        self.block8 = Block8(noReLU=True)\n",
    "        self.conv2d_7b = BasicConv2d(2080, 1536, kernel_size=1, stride=1)\n",
    "        self.avgpool_1a = nn.AvgPool2d(8, count_include_pad=False)\n",
    "        self.last_linear = nn.Linear(1536, num_classes)\n",
    "\n",
    "    def features(self, input):\n",
    "        x = self.conv2d_1a(input)\n",
    "        x = self.conv2d_2a(x)\n",
    "        x = self.conv2d_2b(x)\n",
    "        x = self.maxpool_3a(x)\n",
    "        x = self.conv2d_3b(x)\n",
    "        x = self.conv2d_4a(x)\n",
    "        x = self.maxpool_5a(x)\n",
    "        x = self.mixed_5b(x)\n",
    "        x = self.repeat(x)\n",
    "        x = self.mixed_6a(x)\n",
    "        x = self.repeat_1(x)\n",
    "        x = self.mixed_7a(x)\n",
    "        x = self.repeat_2(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.conv2d_7b(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.avgpool_1a(features)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "def inceptionresnetv2(num_classes=1000, pretrained='imagenet'):\n",
    "    r\"\"\"InceptionResNetV2 model architecture from the\n",
    "    `\"InceptionV4, Inception-ResNet...\" <https://arxiv.org/abs/1602.07261>`_ paper.\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        settings = pretrained_settings['inceptionresnetv2'][pretrained]\n",
    "        assert num_classes == settings['num_classes'], \\\n",
    "            \"num_classes should be {}, but is {}\".format(settings['num_classes'], num_classes)\n",
    "\n",
    "        # both 'imagenet'&'imagenet+background' are loaded from same parameters\n",
    "        model = InceptionResNetV2(num_classes=1001)\n",
    "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "\n",
    "        if pretrained == 'imagenet':\n",
    "            new_last_linear = nn.Linear(1536, 1000)\n",
    "            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n",
    "            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n",
    "            model.last_linear = new_last_linear\n",
    "\n",
    "        model.input_space = settings['input_space']\n",
    "        model.input_size = settings['input_size']\n",
    "        model.input_range = settings['input_range']\n",
    "\n",
    "        model.mean = settings['mean']\n",
    "        model.std = settings['std']\n",
    "    else:\n",
    "        model = InceptionResNetV2(num_classes=num_classes)\n",
    "    return model\n",
    "\n",
    "class MaxPool(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size, stride=1, padding=1, zero_pad=False):\n",
    "        super(MaxPool, self).__init__()\n",
    "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0)) if zero_pad else None\n",
    "        self.pool = nn.MaxPool2d(kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.zero_pad:\n",
    "            x = self.zero_pad(x)\n",
    "        x = self.pool(x)\n",
    "        if self.zero_pad:\n",
    "            x = x[:, :, 1:, 1:]\n",
    "        return x\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, dw_kernel_size, dw_stride,\n",
    "                 dw_padding):\n",
    "        super(SeparableConv2d, self).__init__()\n",
    "        self.depthwise_conv2d = nn.Conv2d(in_channels, in_channels,\n",
    "                                          kernel_size=dw_kernel_size,\n",
    "                                          stride=dw_stride, padding=dw_padding,\n",
    "                                          groups=in_channels, bias=False)\n",
    "        self.pointwise_conv2d = nn.Conv2d(in_channels, out_channels,\n",
    "                                          kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise_conv2d(x)\n",
    "        x = self.pointwise_conv2d(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BranchSeparables(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 stem_cell=False, zero_pad=False):\n",
    "        super(BranchSeparables, self).__init__()\n",
    "        padding = kernel_size // 2\n",
    "        middle_channels = out_channels if stem_cell else in_channels\n",
    "        self.zero_pad = nn.ZeroPad2d((1, 0, 1, 0)) if zero_pad else None\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.separable_1 = SeparableConv2d(in_channels, middle_channels,\n",
    "                                           kernel_size, dw_stride=stride,\n",
    "                                           dw_padding=padding)\n",
    "        self.bn_sep_1 = nn.BatchNorm2d(middle_channels, eps=0.001)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.separable_2 = SeparableConv2d(middle_channels, out_channels,\n",
    "                                           kernel_size, dw_stride=1,\n",
    "                                           dw_padding=padding)\n",
    "        self.bn_sep_2 = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu_1(x)\n",
    "        if self.zero_pad:\n",
    "            x = self.zero_pad(x)\n",
    "        x = self.separable_1(x)\n",
    "        if self.zero_pad:\n",
    "            x = x[:, :, 1:, 1:].contiguous()\n",
    "        x = self.bn_sep_1(x)\n",
    "        x = self.relu_2(x)\n",
    "        x = self.separable_2(x)\n",
    "        x = self.bn_sep_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReluConvBn(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
    "        super(ReluConvBn, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,\n",
    "                              kernel_size=kernel_size, stride=stride,\n",
    "                              bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FactorizedReduction(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FactorizedReduction, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.path_1 = nn.Sequential(OrderedDict([\n",
    "            ('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False)),\n",
    "            ('conv', nn.Conv2d(in_channels, out_channels // 2,\n",
    "                               kernel_size=1, bias=False)),\n",
    "        ]))\n",
    "        self.path_2 = nn.Sequential(OrderedDict([\n",
    "            ('pad', nn.ZeroPad2d((0, 1, 0, 1))),\n",
    "            ('avgpool', nn.AvgPool2d(1, stride=2, count_include_pad=False)),\n",
    "            ('conv', nn.Conv2d(in_channels, out_channels // 2,\n",
    "                               kernel_size=1, bias=False)),\n",
    "        ]))\n",
    "        self.final_path_bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x_path1 = self.path_1(x)\n",
    "\n",
    "        x_path2 = self.path_2.pad(x)\n",
    "        x_path2 = x_path2[:, :, 1:, 1:]\n",
    "        x_path2 = self.path_2.avgpool(x_path2)\n",
    "        x_path2 = self.path_2.conv(x_path2)\n",
    "\n",
    "        out = self.final_path_bn(torch.cat([x_path1, x_path2], 1))\n",
    "        return out\n",
    "\n",
    "\n",
    "class CellBase(nn.Module):\n",
    "\n",
    "    def cell_forward(self, x_left, x_right):\n",
    "        x_comb_iter_0_left = self.comb_iter_0_left(x_left)\n",
    "        x_comb_iter_0_right = self.comb_iter_0_right(x_left)\n",
    "        x_comb_iter_0 = x_comb_iter_0_left + x_comb_iter_0_right\n",
    "\n",
    "        x_comb_iter_1_left = self.comb_iter_1_left(x_right)\n",
    "        x_comb_iter_1_right = self.comb_iter_1_right(x_right)\n",
    "        x_comb_iter_1 = x_comb_iter_1_left + x_comb_iter_1_right\n",
    "\n",
    "        x_comb_iter_2_left = self.comb_iter_2_left(x_right)\n",
    "        x_comb_iter_2_right = self.comb_iter_2_right(x_right)\n",
    "        x_comb_iter_2 = x_comb_iter_2_left + x_comb_iter_2_right\n",
    "\n",
    "        x_comb_iter_3_left = self.comb_iter_3_left(x_comb_iter_2)\n",
    "        x_comb_iter_3_right = self.comb_iter_3_right(x_right)\n",
    "        x_comb_iter_3 = x_comb_iter_3_left + x_comb_iter_3_right\n",
    "\n",
    "        x_comb_iter_4_left = self.comb_iter_4_left(x_left)\n",
    "        if self.comb_iter_4_right:\n",
    "            x_comb_iter_4_right = self.comb_iter_4_right(x_right)\n",
    "        else:\n",
    "            x_comb_iter_4_right = x_right\n",
    "        x_comb_iter_4 = x_comb_iter_4_left + x_comb_iter_4_right\n",
    "\n",
    "        x_out = torch.cat(\n",
    "            [x_comb_iter_0, x_comb_iter_1, x_comb_iter_2, x_comb_iter_3,\n",
    "             x_comb_iter_4], 1)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class CellStem0(CellBase):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right,\n",
    "                 out_channels_right):\n",
    "        super(CellStem0, self).__init__()\n",
    "        self.conv_1x1 = ReluConvBn(in_channels_right, out_channels_right,\n",
    "                                   kernel_size=1)\n",
    "        self.comb_iter_0_left = BranchSeparables(in_channels_left,\n",
    "                                                 out_channels_left,\n",
    "                                                 kernel_size=5, stride=2,\n",
    "                                                 stem_cell=True)\n",
    "        self.comb_iter_0_right = nn.Sequential(OrderedDict([\n",
    "            ('max_pool', MaxPool(3, stride=2)),\n",
    "            ('conv', nn.Conv2d(in_channels_left, out_channels_left,\n",
    "                               kernel_size=1, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(out_channels_left, eps=0.001)),\n",
    "        ]))\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=7, stride=2)\n",
    "        self.comb_iter_1_right = MaxPool(3, stride=2)\n",
    "        self.comb_iter_2_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=5, stride=2)\n",
    "        self.comb_iter_2_right = BranchSeparables(out_channels_right,\n",
    "                                                  out_channels_right,\n",
    "                                                  kernel_size=3, stride=2)\n",
    "        self.comb_iter_3_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=3)\n",
    "        self.comb_iter_3_right = MaxPool(3, stride=2)\n",
    "        self.comb_iter_4_left = BranchSeparables(in_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=3, stride=2,\n",
    "                                                 stem_cell=True)\n",
    "        self.comb_iter_4_right = ReluConvBn(out_channels_right,\n",
    "                                            out_channels_right,\n",
    "                                            kernel_size=1, stride=2)\n",
    "\n",
    "    def forward(self, x_left):\n",
    "        x_right = self.conv_1x1(x_left)\n",
    "        x_out = self.cell_forward(x_left, x_right)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class Cell(CellBase):\n",
    "\n",
    "    def __init__(self, in_channels_left, out_channels_left, in_channels_right,\n",
    "                 out_channels_right, is_reduction=False, zero_pad=False,\n",
    "                 match_prev_layer_dimensions=False):\n",
    "        super(Cell, self).__init__()\n",
    "\n",
    "        # If `is_reduction` is set to `True` stride 2 is used for\n",
    "        # convolutional and pooling layers to reduce the spatial size of\n",
    "        # the output of a cell approximately by a factor of 2.\n",
    "        stride = 2 if is_reduction else 1\n",
    "\n",
    "        # If `match_prev_layer_dimensions` is set to `True`\n",
    "        # `FactorizedReduction` is used to reduce the spatial size\n",
    "        # of the left input of a cell approximately by a factor of 2.\n",
    "        self.match_prev_layer_dimensions = match_prev_layer_dimensions\n",
    "        if match_prev_layer_dimensions:\n",
    "            self.conv_prev_1x1 = FactorizedReduction(in_channels_left,\n",
    "                                                     out_channels_left)\n",
    "        else:\n",
    "            self.conv_prev_1x1 = ReluConvBn(in_channels_left,\n",
    "                                            out_channels_left, kernel_size=1)\n",
    "\n",
    "        self.conv_1x1 = ReluConvBn(in_channels_right, out_channels_right,\n",
    "                                   kernel_size=1)\n",
    "        self.comb_iter_0_left = BranchSeparables(out_channels_left,\n",
    "                                                 out_channels_left,\n",
    "                                                 kernel_size=5, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        self.comb_iter_0_right = MaxPool(3, stride=stride, zero_pad=zero_pad)\n",
    "        self.comb_iter_1_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=7, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        self.comb_iter_1_right = MaxPool(3, stride=stride, zero_pad=zero_pad)\n",
    "        self.comb_iter_2_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=5, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        self.comb_iter_2_right = BranchSeparables(out_channels_right,\n",
    "                                                  out_channels_right,\n",
    "                                                  kernel_size=3, stride=stride,\n",
    "                                                  zero_pad=zero_pad)\n",
    "        self.comb_iter_3_left = BranchSeparables(out_channels_right,\n",
    "                                                 out_channels_right,\n",
    "                                                 kernel_size=3)\n",
    "        self.comb_iter_3_right = MaxPool(3, stride=stride, zero_pad=zero_pad)\n",
    "        self.comb_iter_4_left = BranchSeparables(out_channels_left,\n",
    "                                                 out_channels_left,\n",
    "                                                 kernel_size=3, stride=stride,\n",
    "                                                 zero_pad=zero_pad)\n",
    "        if is_reduction:\n",
    "            self.comb_iter_4_right = ReluConvBn(out_channels_right,\n",
    "                                                out_channels_right,\n",
    "                                                kernel_size=1, stride=stride)\n",
    "        else:\n",
    "            self.comb_iter_4_right = None\n",
    "\n",
    "    def forward(self, x_left, x_right):\n",
    "        x_left = self.conv_prev_1x1(x_left)\n",
    "        x_right = self.conv_1x1(x_right)\n",
    "        x_out = self.cell_forward(x_left, x_right)\n",
    "        return x_out\n",
    "\n",
    "\n",
    "class PNASNet5Large(nn.Module):\n",
    "    def __init__(self, num_classes=1001):\n",
    "        super(PNASNet5Large, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv_0 = nn.Sequential(OrderedDict([\n",
    "            ('conv', nn.Conv2d(3, 96, kernel_size=3, stride=2, bias=False)),\n",
    "            ('bn', nn.BatchNorm2d(96, eps=0.001))\n",
    "        ]))\n",
    "        self.cell_stem_0 = CellStem0(in_channels_left=96, out_channels_left=54,\n",
    "                                     in_channels_right=96,\n",
    "                                     out_channels_right=54)\n",
    "        self.cell_stem_1 = Cell(in_channels_left=96, out_channels_left=108,\n",
    "                                in_channels_right=270, out_channels_right=108,\n",
    "                                match_prev_layer_dimensions=True,\n",
    "                                is_reduction=True)\n",
    "        self.cell_0 = Cell(in_channels_left=270, out_channels_left=216,\n",
    "                           in_channels_right=540, out_channels_right=216,\n",
    "                           match_prev_layer_dimensions=True)\n",
    "        self.cell_1 = Cell(in_channels_left=540, out_channels_left=216,\n",
    "                           in_channels_right=1080, out_channels_right=216)\n",
    "        self.cell_2 = Cell(in_channels_left=1080, out_channels_left=216,\n",
    "                           in_channels_right=1080, out_channels_right=216)\n",
    "        self.cell_3 = Cell(in_channels_left=1080, out_channels_left=216,\n",
    "                           in_channels_right=1080, out_channels_right=216)\n",
    "        self.cell_4 = Cell(in_channels_left=1080, out_channels_left=432,\n",
    "                           in_channels_right=1080, out_channels_right=432,\n",
    "                           is_reduction=True, zero_pad=True)\n",
    "        self.cell_5 = Cell(in_channels_left=1080, out_channels_left=432,\n",
    "                           in_channels_right=2160, out_channels_right=432,\n",
    "                           match_prev_layer_dimensions=True)\n",
    "        self.cell_6 = Cell(in_channels_left=2160, out_channels_left=432,\n",
    "                           in_channels_right=2160, out_channels_right=432)\n",
    "        self.cell_7 = Cell(in_channels_left=2160, out_channels_left=432,\n",
    "                           in_channels_right=2160, out_channels_right=432)\n",
    "        self.cell_8 = Cell(in_channels_left=2160, out_channels_left=864,\n",
    "                           in_channels_right=2160, out_channels_right=864,\n",
    "                           is_reduction=True)\n",
    "        self.cell_9 = Cell(in_channels_left=2160, out_channels_left=864,\n",
    "                           in_channels_right=4320, out_channels_right=864,\n",
    "                           match_prev_layer_dimensions=True)\n",
    "        self.cell_10 = Cell(in_channels_left=4320, out_channels_left=864,\n",
    "                            in_channels_right=4320, out_channels_right=864)\n",
    "        self.cell_11 = Cell(in_channels_left=4320, out_channels_left=864,\n",
    "                            in_channels_right=4320, out_channels_right=864)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.avg_pool = nn.AvgPool2d(11, stride=1, padding=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.last_linear = nn.Linear(4320, num_classes)\n",
    "\n",
    "    def features(self, x):\n",
    "        x_conv_0 = self.conv_0(x)\n",
    "        x_stem_0 = self.cell_stem_0(x_conv_0)\n",
    "        x_stem_1 = self.cell_stem_1(x_conv_0, x_stem_0)\n",
    "        x_cell_0 = self.cell_0(x_stem_0, x_stem_1)\n",
    "        x_cell_1 = self.cell_1(x_stem_1, x_cell_0)\n",
    "        x_cell_2 = self.cell_2(x_cell_0, x_cell_1)\n",
    "        x_cell_3 = self.cell_3(x_cell_1, x_cell_2)\n",
    "        x_cell_4 = self.cell_4(x_cell_2, x_cell_3)\n",
    "        x_cell_5 = self.cell_5(x_cell_3, x_cell_4)\n",
    "        x_cell_6 = self.cell_6(x_cell_4, x_cell_5)\n",
    "        x_cell_7 = self.cell_7(x_cell_5, x_cell_6)\n",
    "        x_cell_8 = self.cell_8(x_cell_6, x_cell_7)\n",
    "        x_cell_9 = self.cell_9(x_cell_7, x_cell_8)\n",
    "        x_cell_10 = self.cell_10(x_cell_8, x_cell_9)\n",
    "        x_cell_11 = self.cell_11(x_cell_9, x_cell_10)\n",
    "        return x_cell_11\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.relu(features)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def pnasnet5large(num_classes=1001, pretrained='imagenet'):\n",
    "    r\"\"\"PNASNet-5 model architecture from the\n",
    "    `\"Progressive Neural Architecture Search\"\n",
    "    <https://arxiv.org/abs/1712.00559>`_ paper.\n",
    "    \"\"\"\n",
    "    if pretrained:\n",
    "        settings = pretrained_settings['pnasnet5large'][pretrained]\n",
    "        assert num_classes == settings[\n",
    "            'num_classes'], 'num_classes should be {}, but is {}'.format(\n",
    "            settings['num_classes'], num_classes)\n",
    "\n",
    "        # both 'imagenet'&'imagenet+background' are loaded from same parameters\n",
    "        model = PNASNet5Large(num_classes=1001)\n",
    "        model.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "\n",
    "        if pretrained == 'imagenet':\n",
    "            new_last_linear = nn.Linear(model.last_linear.in_features, 1000)\n",
    "            new_last_linear.weight.data = model.last_linear.weight.data[1:]\n",
    "            new_last_linear.bias.data = model.last_linear.bias.data[1:]\n",
    "            model.last_linear = new_last_linear\n",
    "\n",
    "        model.input_space = settings['input_space']\n",
    "        model.input_size = settings['input_size']\n",
    "        model.input_range = settings['input_range']\n",
    "\n",
    "        model.mean = settings['mean']\n",
    "        model.std = settings['std']\n",
    "    else:\n",
    "        model = PNASNet5Large(num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import numbers\n",
    "import types\n",
    "import collections\n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "class CenterCrop():\n",
    "    def __init__(self, size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant'):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.padding = padding\n",
    "        self.pad_if_needed = pad_if_needed\n",
    "        self.fill = fill\n",
    "        self.padding_mode = padding_mode\n",
    "    \n",
    "    def __call__(self, img):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img (PIL Image): Image to be cropped.\n",
    "\n",
    "        Returns:\n",
    "            PIL Image: Cropped image.\n",
    "        \"\"\"\n",
    "        if self.padding is not None:\n",
    "            img = TF.pad(img, self.padding, self.fill, self.padding_mode)\n",
    "\n",
    "        # pad the width if needed\n",
    "        if self.pad_if_needed and img.size[0] < self.size[1]:\n",
    "            img = TF.pad(img, (self.size[1] - img.size[0], 0), self.fill, self.padding_mode)\n",
    "        # pad the height if needed\n",
    "        if self.pad_if_needed and img.size[1] < self.size[0]:\n",
    "            img = TF.pad(img, (0, self.size[0] - img.size[1]), self.fill, self.padding_mode)\n",
    "\n",
    "        return TF.center_crop(img, self.size)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(size={0}, padding={1})'.format(self.size, self.padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "test_transform = Compose([\n",
    "    RandomCrop(320, pad_if_needed=True),\n",
    "    RandomHorizontalFlip(),\n",
    "])\n",
    "\n",
    "\n",
    "tensor_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.5949, 0.5611, 0.5185], std=[0.2900, 0.2844, 0.2811]),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "class TTADataset:\n",
    "    def __init__(self, root: Path, df: pd.DataFrame,\n",
    "                 image_transform: Callable, tta: int):\n",
    "        self._root = root\n",
    "        self._df = df\n",
    "        self._image_transform = image_transform\n",
    "        self._tta = tta\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df) * self._tta\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self._df.iloc[idx % len(self._df)]\n",
    "        image = load_transform_image(item, self._root, self._image_transform)\n",
    "        return image, item.id\n",
    "\n",
    "\n",
    "def load_transform_image(\n",
    "        item, root: Path, image_transform: Callable, debug: bool = False):\n",
    "    image = load_image(item, root)\n",
    "    image = image_transform(image)\n",
    "    if debug:\n",
    "        image.save('_debug.png')\n",
    "    return tensor_transform(image)\n",
    "\n",
    "\n",
    "def train_load_transform_image(\n",
    "        item, root: Path, image_transform: Callable, debug: bool = False):\n",
    "    image = load_image(item, root)\n",
    "    image = image_transform(image)\n",
    "    if debug:\n",
    "        image.save('_debug.png')\n",
    "    return train_tensor_transform(image)\n",
    "\n",
    "\n",
    "def load_image(item, root: Path) -> Image.Image:\n",
    "    image = cv2.imread(str(root / f'{item.id}.png'))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return Image.fromarray(image)\n",
    "\n",
    "\n",
    "def get_ids(root: Path) -> List[str]:\n",
    "    return sorted({p.name.split('_')[0] for p in root.glob('*.png')})\n",
    "\n",
    "def load_model(model: nn.Module, path: Path) -> Dict:\n",
    "    state = torch.load(str(path))\n",
    "    model.load_state_dict(state['model'])\n",
    "    print('Loaded model from epoch {epoch}, step {step:,}'.format(**state))\n",
    "    return state\n",
    "\n",
    "def mean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.groupby(level=0).mean()\n",
    "\n",
    "def get_classes(item):\n",
    "    return ' '.join(cls for cls, is_present in item.items() if is_present)\n",
    "\n",
    "def binarize_prediction(probabilities, threshold: float, argsorted=None,\n",
    "                        min_labels=1, max_labels=10):\n",
    "    \"\"\" Return matrix of 0/1 predictions, same shape as probabilities.\n",
    "    \"\"\"\n",
    "    assert probabilities.shape[1] == N_CLASSES\n",
    "    if argsorted is None:\n",
    "        argsorted = probabilities.argsort(axis=1)\n",
    "    max_mask = _make_mask(argsorted, max_labels)\n",
    "    min_mask = _make_mask(argsorted, min_labels)\n",
    "    \n",
    "    # prob_mask = np.zeros_like(probabilities, dtype=np.uint8)\n",
    "    # for i in range(N_CLASSES):\n",
    "    #     prob_mask[:, i] = probabilities[:, i] > thres[i]\n",
    "    # prob_mask = probabilities > threshold\n",
    "    # prob_mask = []\n",
    "    # for prob in probabilities:\n",
    "    #     if prob.max() > 0.4:\n",
    "    #         prob_mask.append(prob > threshold)\n",
    "    #     else:\n",
    "    #         prob_mask.append(prob > 0.05)\n",
    "    # prob_mask = np.array(prob_mask, dtype=np.int)\n",
    "    prob_mask = []\n",
    "    for prob in probabilities:\n",
    "        prob_mask.append(prob > prob.max()/7)\n",
    "        \n",
    "    prob_mask = np.array(prob_mask, dtype=np.int)\n",
    "    \n",
    "    return (max_mask & prob_mask) | min_mask\n",
    "\n",
    "\n",
    "def _make_mask(argsorted, top_n: int):\n",
    "    mask = np.zeros_like(argsorted, dtype=np.uint8)\n",
    "    col_indices = argsorted[:, -top_n:].reshape(-1)\n",
    "    row_indices = [i // top_n for i in range(len(col_indices))]\n",
    "    mask[row_indices, col_indices] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'batch_size':64,\n",
    "    'tta':2,\n",
    "    'use_cuda':1,\n",
    "    'workers':8,\n",
    "    'threshold':0.1,\n",
    "    'max_labels':10,\n",
    "    'output':'submission.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model):\n",
    "    feature_dim = model.last_linear.in_features\n",
    "    class AvgPool(nn.Module):\n",
    "        def forward(self, x):\n",
    "            # print (x.size())\n",
    "            return F.avg_pool2d(x, x.shape[2:])\n",
    "    model.avg_pool = AvgPool()\n",
    "    model.avgpool = AvgPool()\n",
    "    model.last_linear = nn.Linear(feature_dim, N_CLASSES)\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model = model.cuda()\n",
    "    return model\n",
    "    \n",
    "def test(model, loader, model_path, multi=False, half=False):\n",
    "    load_model(model, model_path / 'best-model.pt')\n",
    "    df = predict(model, loader, use_cuda=args['use_cuda'], half=half)\n",
    "    return df\n",
    "    \n",
    "def predict(model, loader, use_cuda: bool, half=False):\n",
    "    model.eval()\n",
    "    all_outputs, all_ids = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, ids in tqdm_notebook(loader):\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = torch.sigmoid(model(inputs))\n",
    "            # outputs = model(inputs)\n",
    "            all_outputs.append(outputs.detach().cpu().numpy())\n",
    "            all_ids.extend(ids)\n",
    "    df = pd.DataFrame(\n",
    "        data=np.concatenate(all_outputs),\n",
    "        index=all_ids,\n",
    "        columns=map(str, range(N_CLASSES)))\n",
    "    df = mean_df(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def randomString2(stringLength=8):\n",
    "    \"\"\"Generate a random string of fixed length \"\"\"\n",
    "    letters= string.ascii_lowercase\n",
    "    return ''.join(random.sample(letters,stringLength))\n",
    "\n",
    "test_root = DATA_ROOT /'test'\n",
    "test_df = pd.read_csv(DATA_ROOT / 'sample_submission.csv')\n",
    "# df = pd.concat([df]*5, ignore_index=True)\n",
    "# df['new_id'] = [randomString2() for i in range(len(df))]\n",
    "loader = DataLoader(\n",
    "        dataset=TTADataset(test_root, test_df, test_transform, tta=args['tta']),\n",
    "        shuffle=False,\n",
    "        batch_size=args['batch_size'],\n",
    "        num_workers=args['workers'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 12, step 24,420\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de53ab967cf04d5abffb0c2c58323609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 17, step 35,520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73da1ce3c2fd4ab8be0f44c411fc1f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 18, step 37,723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a76b5341ee04503a4978b3d151c8b53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 17, step 35,520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9a48e993ba400c96d2699b74db76b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 19, step 39,942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670445fd518c477db06d1a79b31cd086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 19, step 29,970\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5002a2275fcd44ff99aff4b59c6114ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 19, step 29,970\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f90fec0ee341a3a2972e9c976da328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 15, step 23,310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ede1286ad7472e80a6d5e3e399363f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 13, step 26,628\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f340787dab164f568119205db30e31e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 18, step 37,723\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9480e811ef420eaa223c496b07d5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved predictions to 05_28_se101.h5\n",
      "Loaded model from epoch 27, step 43,290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a51a1e1a9b461bbb82c8cb90cf53cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 24, step 51,037\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8ce37dd5254ba3904f5d4ca1c4b140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 28, step 60,360\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3934739e314591874d65f822a8d13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 30, step 64,351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5015ee9d6454dc6bebff7dbb2934eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 28, step 59,913\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b04635e0f34a6baa80022a83b8f0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved predictions to 05_30_inres2.h5\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "model = se_resnext101_32x4d(pretrained=None)\n",
    "model = create_model(model)\n",
    "dfs = []\n",
    "for i in range(10):\n",
    "    df = test(model, loader, Path(f'../input/05-28-results/05_28_results/05_28_results/model_05_28_se101_{i+1}/'), multi=True)\n",
    "    gc.collect()\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = mean_df(df)\n",
    "out_path = '05_28_se101.h5'\n",
    "df.to_hdf(out_path, 'prob', index_label='id')\n",
    "print(f'Saved predictions to {out_path}')\n",
    "'''\n",
    "dfs = []\n",
    "for i in range(10):\n",
    "    model = inceptionv4(pretrained=False)\n",
    "    df = test(model, loader, Path(f'../input/05-29-results/05_29_results/05_29_results/model_05_29_inv4_{i+1}/'), multi=True)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = mean_df(df)\n",
    "out_path = '05_29_inv4.h5'\n",
    "df.to_hdf(out_path, 'prob', index_label='id')\n",
    "print(f'Saved predictions to {out_path}')\n",
    "'''\n",
    "dfs = []\n",
    "model = inceptionresnetv2(pretrained=False)\n",
    "model = create_model(model)\n",
    "for i in range(5,10):\n",
    "    df = test(model, loader, Path(f'../input/05-30-results/05_30_results/05_30_results/model_05_30_inres2_{i+1}/'), multi=True)\n",
    "    gc.collect()\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = mean_df(df)\n",
    "out_path = '05_30_inres2.h5'\n",
    "df.to_hdf(out_path, 'prob', index_label='id')\n",
    "print(f'Saved predictions to {out_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 13, step 39,948\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0750d5d307bd49b895da73a5d03c8496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 15, step 46,606\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a7b6ce801441ee848be66b403194cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 16, step 49,920\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f31bb6ad3184c22aa715868d312540f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 18, step 56,593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a71c617d15f4be7b634f1f434362ef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 15, step 46,592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edfef22095ee45e3b7406dd683a59750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved predictions to 06_01_se154.h5\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "model = senet154(pretrained=None)\n",
    "model = create_model(model)\n",
    "for i in range(5):\n",
    "    df = test(model, loader, Path(f'../input/06-01-results/06_01_results/06_01_results/model_06_01_se154_{i+1}/'), multi=True)\n",
    "    gc.collect()\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = mean_df(df)\n",
    "out_path = '06_01_se154.h5'\n",
    "df.to_hdf(out_path, 'prob', index_label='id')\n",
    "print(f'Saved predictions to {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from epoch 17, step 71,143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a884ad2ccc44d6fa366ec22694e12ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 18, step 75,616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073dc6eb572046638d8ed71efdc2e8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 20, step 84,303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9758ad8361e045a4864e8f9de9be0d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 19, step 79,902\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cd00bb22f534683b383abc67aa70234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded model from epoch 28, step 119,826\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da96955830d547c38be51ed4ebfc8343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=233), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved predictions to 06_02_pnas.h5\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "model = pnasnet5large(pretrained=False)\n",
    "model = create_model(model)\n",
    "for i in range(5):\n",
    "    df = test(model, loader, Path(f'../input/06-02-results/06_02_results/06_02_results/model_06_02_pnas_{i+1}/'), multi=True)\n",
    "    gc.collect()\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = mean_df(df)\n",
    "out_path = '06_02_pnas.h5'\n",
    "df.to_hdf(out_path, 'prob', index_label='id')\n",
    "print(f'Saved predictions to {out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "results =  [f for f in os.listdir('./') if f.endswith('.h5')]\n",
    "\n",
    "for prediction in results:\n",
    "    df = pd.read_hdf(prediction, index_col='id')\n",
    "    df = df.reindex(test_df.id)\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "df = mean_df(df)\n",
    "pred = df.values\n",
    "# def sigmoid(x): \n",
    "#     return 1.0 / (1.0 + np.exp(-x))\n",
    "# pred = sigmoid(pred)\n",
    "df[:] = binarize_prediction(pred, threshold=args['threshold'], max_labels=args['max_labels'])\n",
    "df = df.apply(get_classes, axis=1)\n",
    "df.name = 'attribute_ids'\n",
    "df.to_csv(args['output'], header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,attribute_ids\r\n",
      "10023b2cc4ed5f68,195 223 289 343 344 369 587 766 1059\r\n",
      "100fbe75ed8fd887,93 231 1039\r\n",
      "101b627524a04f19,79 784 1037\r\n",
      "10234480c41284c6,13 147 725 738 776 813 830 1046\r\n",
      "1023b0e2636dcea8,147 322 584 813 954 1046 1092\r\n",
      "1039cd6cf85845c,13 405 903 1092\r\n",
      "103a5b3f83fbe88,194 671 813 1020 1057 1092\r\n",
      "10413aaae8d6a9a2,147 616 698 813 1046 1092\r\n",
      "10423822b93a65ab,51 121 483 738 813 1039\r\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
